RelayTive is a privacy-first iOS app that enables live translation of atypical (nonstandard or neurodivergent) speech patterns into clear, typical languageâ€”entirely on-device.
It uses Appleâ€™s CoreML and the HuBERT model for secure, customizable, real-time communication support, especially for nonverbal or speech-atypical individuals and their caregivers.

ğŸš€ Features
Three-tab SwiftUI interface:

Translation â€” Real-time speech translation for atypical-to-typical language

Training â€” Record new speech samples and explanations to expand personalized vocabulary

Examples â€” Review, edit, and manage all trained utterances and their mapped meanings

On-device HuBERT CoreML integration:

No internet required; all processing happens locally for privacy

Neural Engine accelerated for real-time, battery-efficient translation

Customizable Training:

Caregivers can add new speech patterns (audio + literal explanation) to teach the app unique utterances

All mappings are user-created and editable; no predefined or canned examples

Live Speech Recognition:

Real iOS speech recognition for explanations

Manual entry supported as fallback

Accessibility:

Clean, guided workflow for non-technical users

No data ever leaves the device

ğŸ› ï¸ Architecture
Swift 5+, modular, pure SwiftUI app structure

CoreML model: HuBERT (RelayTive_HuBERT.mlpackage) for robust audio embedding extraction

Managers:

AudioManager (audio recording/playback)

DataManager (persistent utterance mapping)

TranslationEngine (HuBERT inference and translation logic)

SpeechRecognitionManager (iOS speech-to-text for explanations)

ğŸ—‚ï¸ Project Structure
Copy
Edit
RelayTive/
â”œâ”€â”€ RelayTive.xcodeproj/
â”œâ”€â”€ RelayTive/
â”‚   â”œâ”€â”€ Assets.xcassets/
â”‚   â”œâ”€â”€ ContentView.swift
â”‚   â”œâ”€â”€ Managers/
â”‚   â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ Views/
â”‚   â””â”€â”€ RelayTiveApp.swift
â”œâ”€â”€ RelayTiveTests/
â”œâ”€â”€ RelayTiveUITests/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
âš¡ Getting Started
Prerequisites
Xcode 15+ (macOS)

iOS 17+ device for full speech recognition (simulator support limited)

Setup
Clone the repo:

sh
Copy
Edit
git clone <your_repo_url>
cd relaytive
Open the project in Xcode:

Double-click RelayTive.xcodeproj

Add HuBERT model:

The model file RelayTive_HuBERT.mlpackage must be added to RelayTive/Models/
(The model is not tracked in Git due to size/licensing; see .gitignore.)

Set privacy permissions:

Open Info.plist

Add:

NSMicrophoneUsageDescription = â€œRelayTive needs microphone access to translate speechâ€

NSSpeechRecognitionUsageDescription = â€œRelayTive uses speech recognition for caregiver explanationsâ€

Build and run on device.

ğŸ’¡ How It Works
Training:

Record an atypical utterance (userâ€™s unique vocalization).

Record or type the literal typical-language explanation.

Save the mapping; review and edit in Examples.

Translation:

Record new utterance in Translation tab.

If a match (or near-match) exists, the mapped meaning is displayed in real-time.

All data and mappings are local and user-controlled.

â— Notes
No predefined mappings: All examples come from the user. The app starts empty.

Model input/output keys: See Model_Key_Update_Guide.md if your HuBERT model uses nonstandard keys.

Troubleshooting: See Xcode_Integration_Checklist.md and Cache_And_Metal_Issues.md.

ğŸ“„ License
Proprietary. All rights reserved.
Contact the project owner for commercial or academic use.

ğŸ™‹ Support
For bugs, feature requests, or support, please open an issue or contact the maintainer.
